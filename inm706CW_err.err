[38;5;127mlibs[0m/[38;5;172mnvidia-cuda[0m/[38;5;67m11.2.0[0m/[38;5;68mbin[0m
 |
 [0;32mOK[0m
Downloading: "https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth" to /mnt/data/public/torch/hub/checkpoints/efficientnet-b0-355c32eb.pth
  0%|          | 0.00/20.4M [00:00<?, ?B/s]  2%|â–         | 480k/20.4M [00:00<00:04, 4.86MB/s]  8%|â–Š         | 1.53M/20.4M [00:00<00:02, 8.53MB/s] 15%|â–ˆâ–Œ        | 3.14M/20.4M [00:00<00:01, 12.3MB/s] 23%|â–ˆâ–ˆâ–Ž       | 4.70M/20.4M [00:00<00:01, 13.9MB/s] 31%|â–ˆâ–ˆâ–ˆ       | 6.33M/20.4M [00:00<00:00, 15.0MB/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 7.92M/20.4M [00:00<00:00, 15.5MB/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9.55M/20.4M [00:00<00:00, 16.0MB/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 11.2M/20.4M [00:00<00:00, 16.3MB/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 12.7M/20.4M [00:00<00:00, 16.0MB/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 14.3M/20.4M [00:01<00:00, 16.0MB/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 15.9M/20.4M [00:01<00:00, 16.2MB/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17.5M/20.4M [00:01<00:00, 16.4MB/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 19.0M/20.4M [00:01<00:00, 16.3MB/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20.4M/20.4M [00:01<00:00, 15.3MB/s]
wandb: Currently logged in as: julian-jimenez-nimmo (citai). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.2
wandb: Run data is saved locally in /users/adgj619/inm706_cw/wandb/run-20240512_190213-jqt2utgx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logger-FLICKR-efficientnet-baseline
wandb: â­ï¸ View project at https://wandb.ai/citai/INM706-FINAL
wandb: ðŸš€ View run at https://wandb.ai/citai/INM706-FINAL/runs/jqt2utgx
Traceback (most recent call last):
  File "/users/adgj619/inm706_cw/train_flickr.py", line 413, in <module>
    main()
  File "/users/adgj619/inm706_cw/train_flickr.py", line 400, in main
    train(train_dataloader, val_dataloader, encoder, decoder_cap, n_epochs, logger, train_dataset,
  File "/users/adgj619/inm706_cw/train_flickr.py", line 313, in train
    loss = train_epoch(train_dataloader, encoder, decoder_cap,encoder_optimizer, decoder_optimizer_cap,
  File "/users/adgj619/inm706_cw/train_flickr.py", line 250, in train_epoch
    caption_outputs, _, attention_weights = decoder_cap(encoder_outputs, meme_captions,
  File "/users/adgj619/.pyenv/versions/inm706_cw/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/adgj619/.pyenv/versions/inm706_cw/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1561, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/users/adgj619/inm706_cw/models_captioning.py", line 233, in forward
    caption_outputs, hidden, attention = self.generate_caption(feature_outputs, caption, target_tensor,
  File "/users/adgj619/inm706_cw/models_captioning.py", line 251, in generate_caption
    decoder_output, decoder_hidden, attn_weights = self.attention_function(decoder_input, decoder_hidden,
  File "/users/adgj619/inm706_cw/models_captioning.py", line 284, in forward_step
    hidden = self.init_h(mean_encoder_out)  # (batch_size, decoder_dim)
  File "/users/adgj619/.pyenv/versions/inm706_cw/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/adgj619/.pyenv/versions/inm706_cw/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/adgj619/.pyenv/versions/inm706_cw/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 116, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (8x1280 and 2048x512)
wandb: - 0.006 MB of 0.006 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: ðŸš€ View run logger-FLICKR-efficientnet-baseline at: https://wandb.ai/citai/INM706-FINAL/runs/jqt2utgx
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240512_190213-jqt2utgx/logs
